---
title: "Lab 4: Week 4"
output: html_document
html_document:
  toc: true
  toc_depth: 3
  toc_float: true
  number_sections: true
---

```{r Lab1c, echo=FALSE, cache=FALSE, message=FALSE, warning=FALSE}
#source(here::here("Tutorial GLMM","assets","lab_first_chunk.R"))
show_supp = FALSE
show_q = TRUE
show_s = FALSE ## EDIT to TRUE when generating solution
show_type = ifelse(show_s, "markdown", "hide")
knitr::opts_chunk$set(results = show_type)


knitr::opts_chunk$set(collapse = TRUE,
    echo = TRUE,
    comment = NA,
    fig.align = "center",
    fig.height = 5,
    fig.width = 7, 
    warning=FALSE
)

options(digits=3)

suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(ggplot2))
```

# Poison linear, and logistic regression


## Poisson linear model
 

### Exercise 1: Discoveries


The dataset discoveries lists the numbers of great inventions and scientific discoveries from 1860 to 1959.

```{r}
dat <- data.frame(year=1860:1959,discoveries=as.vector(discoveries))
```

```{r e1a, exercise=TRUE, exercise.lines = 5}
summary(dat)
```

```{r, echo=FALSE}
mod0 <- glm(discoveries~1,data=dat,family=poisson)
mod1 <- glm(discoveries~year,data=dat,family=poisson)
mod2 <- glm(discoveries~poly(year,2),data=dat,family=poisson)
mod3 <- glm(discoveries~poly(year,3),data=dat,family=poisson)
```

Plot the discoveries over time and comment on the trend, if any.

```{r e1b, eval=FALSE}
plot(<x value>,<y value>)
```

Fit a Poisson response model with a constant term

```{r e1c, eval=FALSE}
mod0 <- glm(<equation>,data=dat,family=<family>)
summary(mod0)
``` 

 

Compute the mean number of discoveries per year.

```{r e1d, eval=FALSE}
mean(<variable>)
```

 


What is the reationship between this eamn and the coefficient seen in
the model?

```{r e1e, eval=FALSE}
exp(<value>)
```

 

Make a table of how many years had zero, one, two, three, etc
discoveries. 

```{r e1f, eval=FALSE}
table(<variable>)
```

 

Fit a model with year as a predictor.

```{r e1g, eval=FALSE}
mod1 <- glm(<equation>,data=dat,family=<family>)
summary(mod1)
```

 


Plot the results using the sjPlot package

```{r e1h, eval=FALSE}
library(sjPlot)
plot_model(mod1, type = "pred", terms =  c("year"), show.data = TRUE) +
  theme_bw(base_size = 12) 
```


 


Fit a model with a quadratic polynomial for year as a predictor.
Hint: Use the poly function.

```{r e1i, eval=FALSE}
mod2 <- glm(<equation>,data=dat,family=<family>)
summary(mod2)
```

 

Plot the results using the sjPlot package

```{r e1j, eval=FALSE}
plot_model(mod2, type = "pred", terms = <variable>, show.data = TRUE) +
  theme_bw(base_size = 12) 
```

 


Fit a model with a cubic polynomial for year as a predictor.

```{r e1k, eval=FALSE}
mod3 <- glm(<equation>,data=dat,family=<family>)
summary(mod3)
```
 

Plot the results using the sjPlot package

```{r e1l, eval=FALSE}
plot_model(mod3, type = "pred", terms = <variable>, show.data = TRUE) +
  theme_bw(base_size = 12) 
```

 

Calculate the AIC values for mod0, mod1 and mod2.

```{r e1m, eval=FALSE}
AIC(<model>)
AIC(<model>)
AIC(<model>)
AIC(<model>)
```

 
Which model is the best model according to the AIC?
 
Use the predict function to predict the mean number of discoveries in 1950 using the model with the smallest AIC.

### Exercise 2:  Galapagos Species


There are 30 Galapagos islands and 7 variables in the dataset. 
The relationship between the number of plant species and several geographic variables is of interest. 
The dataset contains the following variables

+ Species: the number of plant species found on the island

+ Endemics: the number of endemic species

+ Area: the area of the island (km$^2$)

+ Elevation: the highest elevation of the island (m)

+ Nearest: the distance from the nearest island (km)

+ Scruz: the distance from Santa Cruz island (km)

+ Adjacent: the area of the adjacent island (square km)

The original dataset contained several missing values which have been filled for convenience.

First we load in the data and summarize the columns:

```{r}
data(gala, package="faraway")
summary(gala)
```

```{r, echo=FALSE}
mod1 <- glm(Species ~ log(Area) + log(Adjacent) + log(Elevation) + Nearest + Scruz, data=gala, family = poisson)
mod2 <- glm(Species ~ log(Area) + log(Adjacent) + Scruz, data=gala, family = poisson)
```

Summarize the data in the gala dataset.

```{r e2a, eval=FALSE}
summary(<dataset>)
```

 
Which variables appear to be on a very differnt scale than the other variables?

 

Fit a Poisson linear model with Species as the response,
and log(Area), log(Adjacent), log(Elevation), Nearest,
and Scruz as predictors.

```{r e2b, eval=FALSE}
mod1 <- glm(<equation here>, data=gala, family=<family>)
summary(mod1)
```
 
Which variables are statistically significant?
 

Refit the model removing any predictors that are not statistically
significant.

```{r e2c, eval=FALSE}
mod2 <- glm(<equation here>, data=gala, family=<family>)
summary(mod2)
```
 
 


## Logistic regression

### Exercise 3:  Pima Indians diabetes

The National Institute of Diabetes and Digestive and Kidney Disease conducted a
survey on 768 adult female Pima Indians living near Pheonix. The purpose of the study
was to investigate factors related to diabetes. Let's look at a summary of the data.

```{r}
data(pima, package="faraway")
```

```{r e3a, eval=TRUE}
summary(pima)
```

Observe that glucose, diastolic, triceps, insulin and bmi are values that must
be strictly positive. Any values that are recorded as 0 are implicitly missing
values. The next chunk changes the implicit missing values to NAs, and then
removes any rows containing NAs. Some packages will implicitly do this for you,
but it is better to deal with missing values explicitly.

```{r}
library(naniar)
pima2 <- pima %>%  
  replace_with_na(pima,replace=list(glucose=0.0,
                               diastolic=0.0,
                               triceps=0.0,
                               insulin=0.0,
                               bmi=0.0)) %>%
  na.omit()
```

```{r e3b, eval=TRUE}
summary(pima2)
```

Fit a model using all of the predictors.

```{r e3c, eval=FALSE}
mod1 <- glm(<equation>, data=pima2, family=<family>)
summary(<model>)
```

 

Use the sjPlot function to display a summary table of the fit.

```{r e3d, eval=FALSE}
library(sjPlot)
tab_model(mod1, transform = NULL)
```
 
Remove any variables with p-values above 0.1 and refit the model.

```{r e3e, eval=FALSE}
mod2 <- glm(<equation>, data=pima2, family=<family>)
tab_model(mod2, transform = NULL)
```


### Exercise 4:  Cars

The in-built data set "mtcars" describes different models of a car with their various engine specifications. In "mtcars" data set, the transmission mode (automatic or manual) is described by the column am which is a binary value (0 or 1). We can create a logistic regression model between the columns "am" and 3 other columns - hp, wt and cyl.



```{r}
input <- mtcars[,c("am","cyl","hp","wt")]
print(head(input))
```


Use the glm() function to create a logistic regression model with am as the response, and cyl, hp and wt as predictors,   and get its summary for analysis.

```{r, eval=FALSE}
am.data1 = glm(formula = <code>, data = mtcars, family = <code>)
print(summary(am.data1))
```

Comment on the significance of each term.


Plot the effect of wt and cyl.

```{r, eval=FALSE}
plot_model(<code>, type = "pred", terms = <code>, show.data = TRUE) +
  theme_bw(base_size = 12) 
```

Plot the effect of hp and cyl.

```{r, eval=FALSE}
plot_model(<code>, type = "pred", terms = <code>, show.data = TRUE) +
  theme_bw(base_size = 12) 
```


Calculate the AIC and BIC values

```{r, eval=FALSE}
AIC(am.data1)
BIC(am.data1)
```

Remove cyl and refit the model. Is the fit improved?

```{r, eval=FALSE}
am.data2 = glm(formula = <code>, data = mtcars, family = <code>)
print(summary(am.data2))
```

```{r, eval=FALSE}
AIC(<code>)
BIC(<code>)
```

Both AIC and BIC have decreased indicating an improvement.




Check for an interaction effect between hp and wt.

```{r, eval=FALSE}
am.data2 = glm(formula = <code>, data = mtcars, family = <code>)
print(summary(am.data2))
```

## Linear mixed models

### Random intercept model

The denim dataset concern the amount of waste in material cutting for a jeans
manufacturer due to five suppliers.
Typically, a supplier wastes more material than the target based on the algorithm although occasionally they waste less. The percentage of waste relative to target was collected weekly for the 5 suppliers. 95 observations were recorded.

```{r}
library(faraway)
data(denim)
```

 

```{r, e4a, eval=TRUE}
head(denim)
```

Fit a linear model using supplier as a categorical 
variable.

```{r, e4b, eval=FALSE}
mod1 <- lm(<equation>,data=denim)
summary(mod1)
```
 

Is supplier significant?

Plot a diagnostic plots for the linear model.

```{r e4c, eval=FALSE}
par(mfrow=c(2,2))
plot(<code>)
```

 
Comment on the diagnostic plots.

Fit a random intercept model with supplier as
the group identifier.

```{r e4d, eval=FALSE}
library(lme4)
mod2 <- lmer(<equation>,data=denim)
summary(mod2)
```


 

Test the significance of the supplier term.


```{r e4e, eval=FALSE}
library(RLRsim)
mod3 <- lmer(<equation>,data=denim)  
exactRLRT(mod3)
```

 
What conclusion do you draw?



### Egg Production

The eggprod dataset concerns an experiment where 6 pullets where placed
into each of 12 pens. Four blocks where fromed from groups of 3 pens based
on location. Three treatments where applied. The number of eggs was recorded.

```{r}
library(faraway)
data("eggprod")
```

```{r, e5a, eval=TRUE}
head(eggprod)
```

Fit a fixed effects model for the number of eggs produced with the treatments
and blocks as predictors. Determine the significance of the two predictors
and perform a basic diagnostic check.

```{r e5b, eval=FALSE}
mod1 <- lm(eggs~treat+block,data=<code>)
summary(<code>)

par(mfrow=c(2,2))
plot(<code>)
```

 

Fit a model for the number of eggs produce with the treatmens as fixed 
effects and the blocks as random effects. Which treatment is best in
terms of maximizing production according to the model? Is it significantly
better than the other two treatments (use the Kenward-Roger method).

```{r, e5c, eval=FALSE}
mod2 <- lmer(eggs~treat + (1|block), data=eggprod, REML=FALSE)  
summary(mod2)

mod3 <- lmer(<code>, data=eggprod, REML=FALSE)  

library(pbkrtest)
KRmodcomp(mod2,mod3)
```


 

Test the significance of the blocks. Does the outcome agree with the fixed
effects results?







